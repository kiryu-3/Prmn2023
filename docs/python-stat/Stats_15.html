<!DOCTYPE html>
<html>
<head>
<title>Stats_15.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="%E5%9B%9E%E5%B8%B0%E5%88%86%E6%9E%90">回帰分析</h1>
<ul>
<li><a href="#%E5%9B%9E%E5%B8%B0%E5%88%86%E6%9E%90">回帰分析</a>
<ul>
<li><a href="#%E8%AA%AC%E6%98%8E%E5%A4%89%E6%95%B0%E3%81%A8%E7%9B%AE%E7%9A%84%E5%A4%89%E6%95%B0">説明変数と目的変数</a></li>
<li><a href="#%E5%9B%9E%E5%B8%B0">回帰</a>
<ul>
<li><a href="#%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%97%E6%B3%95">最小二乗法</a></li>
</ul>
</li>
<li><a href="#%E5%8D%98%E5%9B%9E%E5%B8%B0%E5%88%86%E6%9E%90">単回帰分析</a>
<ul>
<li><a href="#%E5%8D%98%E5%9B%9E%E5%B8%B0%E5%88%86%E6%9E%90%E3%81%AE%E6%B5%81%E3%82%8C">単回帰分析の流れ</a>
<ul>
<li><a href="#%E3%83%A2%E3%83%87%E3%83%AB%E3%82%92%E6%B1%BA%E3%82%81%E3%82%8B">モデルを決める</a></li>
<li><a href="#%E6%90%8D%E5%A4%B1%E9%96%A2%E6%95%B0%E3%82%92%E6%B1%BA%E3%82%81%E3%82%8B">損失関数を決める</a></li>
<li><a href="#%E6%90%8D%E5%A4%B1%E9%96%A2%E6%95%B0%E3%82%92%E6%9C%80%E5%B0%8F%E5%8C%96%E3%81%99%E3%82%8B">損失関数を「最小化」する</a></li>
</ul>
</li>
<li><a href="#python%E3%81%AB%E3%82%88%E3%82%8B%E6%8F%8F%E7%94%BB">Pythonによる描画</a></li>
<li><a href="#%E9%83%BD%E9%81%93%E5%BA%9C%E7%9C%8C%E3%83%87%E3%83%BC%E3%82%BF%E3%81%A7%E5%8D%98%E5%9B%9E%E5%B8%B0%E5%88%86%E6%9E%90">都道府県データで単回帰分析</a></li>
<li><a href="#%E8%AA%AC%E6%98%8E%E5%A4%89%E6%95%B0%E3%81%A8%E7%9B%AE%E7%9A%84%E5%A4%89%E6%95%B0%E3%81%AE%E5%85%A5%E3%82%8C%E6%9B%BF%E3%81%88">説明変数と目的変数の入れ替え</a></li>
</ul>
</li>
<li><a href="#%E6%B1%BA%E5%AE%9A%E4%BF%82%E6%95%B0">決定係数</a>
<ul>
<li><a href="#%E6%B1%BA%E5%AE%9A%E4%BF%82%E6%95%B0%E3%81%AE%E5%AE%9A%E7%BE%A9">決定係数の定義</a></li>
<li><a href="#python%E3%81%AB%E3%82%88%E3%82%8B%E6%B1%BA%E5%AE%9A%E4%BF%82%E6%95%B0%E3%81%AE%E5%B0%8E%E5%87%BA">Pythonによる決定係数の導出</a></li>
</ul>
</li>
<li><a href="#%E9%87%8D%E5%9B%9E%E5%B8%B0%E5%88%86%E6%9E%90">重回帰分析</a>
<ul>
<li><a href="#%E9%87%8D%E5%9B%9E%E5%B8%B0%E5%88%86%E6%9E%90%E3%81%AE%E6%B5%81%E3%82%8C">重回帰分析の流れ</a>
<ul>
<li><a href="#%E3%83%A2%E3%83%87%E3%83%AB%E3%82%92%E6%B1%BA%E3%82%81%E3%82%8B-1">モデルを決める</a></li>
<li><a href="#%E6%90%8D%E5%A4%B1%E9%96%A2%E6%95%B0%E3%82%92%E6%B1%BA%E3%82%81%E3%82%8B-1">損失関数を決める</a></li>
<li><a href="#%E6%90%8D%E5%A4%B1%E9%96%A2%E6%95%B0%E3%82%92%E6%9C%80%E5%B0%8F%E5%8C%96%E3%81%99%E3%82%8B-1">損失関数を「最小化」する</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E7%B5%82%E3%82%8F%E3%82%8A%E3%81%AB">終わりに</a></li>
</ul>
<pre class="hljs"><code><div><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns
<span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LinearRegression
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> r2_score
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
</div></code></pre>
<div style="page-break-before:always"></div>
<h2 id="%E8%AA%AC%E6%98%8E%E5%A4%89%E6%95%B0%E3%81%A8%E7%9B%AE%E7%9A%84%E5%A4%89%E6%95%B0">説明変数と目的変数</h2>
<p>「何かの原因となっている変数」を<strong>説明変数</strong>、<br>
「その原因を受けて発生した結果となっている変数」を<strong>目的変数</strong>、<br>
といいます。</p>
<p>説明変数と目的変数にはいくつかの表現があります。<br>
詳しくは<a href="https://bit.ly/3kl6M6S">こちら</a>を参照してください。</p>
<h2 id="%E5%9B%9E%E5%B8%B0">回帰</h2>
<p><strong>目的変数</strong>$y$について<strong>説明変数</strong>$x$を使った式で表すことを<strong>回帰</strong>といいます。</p>
<p>例として、身長から体重を予測することを考えてみましょう。</p>
<p>身長170cmである場合の平均的な体重を予測しようとしたとき、<br>
「身長が170cm」という条件付きでの体重の平均を，<strong>条件付き平均</strong>といいます。</p>
<p>この<strong>条件付き平均</strong>を以下のような<strong>回帰直線</strong>（<strong>線形回帰</strong>ともいう）を使って求めるのが回帰です。</p>
<p>$$
\hat{y}=\theta_0+\theta_1x_1+\theta_2x_2+ … + \theta_nx_n
$$</p>
<p>$\hat{y}$は、$x$に対する$y$の条件付き平均です。</p>
<div style="page-break-before:always"></div>
<h3 id="%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%97%E6%B3%95">最小二乗法</h3>
<p>パラメータ $\theta_0 , \theta_1 , \theta_2, ･･･ \theta_n,$ を求めることができれば、<br>
回帰直線が一つに定まります。</p>
<p>予測値と実測値の差のことを<strong>残差</strong>と呼びます。<br>
（よく聞く「<strong>誤差</strong>」というワードと「<strong>残差</strong>」の違いについては<a href="https://bit.ly/3KHNXFo">こちら</a>を参照してください。）</p>
<p><strong>残差の二乗和を最小にする</strong>アルゴリズムを<strong>最小二乗法</strong>と呼びます。</p>
<p>特徴量が一つの場合を例とします。<br>
このとき、回帰直線は以下のように定まるものとします。</p>
<p>$$
\hat{y} = a + bx　(a=\theta_0 , b=\theta_1)
$$</p>
<p>$\hat{y}$ は<strong>条件付き平均</strong>、つまり予測値であるので、<br>
実際のデータとは多少の誤差があると考えられます。</p>
<p><img src="https://imgur.com/pAMsBS6.png" alt="リンクテキスト"></p>
<p>残差は以下のようにして求めることができます。</p>
<p><img src="https://imgur.com/PMQhVAu.png" alt="リンクテキスト"></p>
<div style="page-break-before:always"></div>
<p><strong>残差の二乗の和</strong>が最小になるような $a$ と$b$ を求めるのが、最小二乗法になります。</p>
<p><img src="stats15-1.png" alt="リンクテキスト"></p>
<p>上の式のように、「<strong>予測値と実測値のずれを計算する関数</strong>」のことを<strong>損失関数</strong>と呼びます。</p>
<p>今回の場合であれば後は $a$ と $b$ の値を求めて、<br>
損失関数を「最小化」していくのみとなります。</p>
<p>ここまでは特徴量が一つの場合を見てきましたが、特徴量が複数になっても基本的な流れは同じです。</p>
<div style="page-break-before:always"></div>
<h2 id="%E5%8D%98%E5%9B%9E%E5%B8%B0%E5%88%86%E6%9E%90">単回帰分析</h2>
<p>回帰直線 $\hat{y}=a+bx$ では、説明変数が$x$の一つだけ用いられています。</p>
<p>このような<strong>単回帰式</strong>を求めることを<strong>単回帰分析</strong>といいます。</p>
<h3 id="%E5%8D%98%E5%9B%9E%E5%B8%B0%E5%88%86%E6%9E%90%E3%81%AE%E6%B5%81%E3%82%8C">単回帰分析の流れ</h3>
<p>① <strong>モデル</strong>を決める<br>
② <strong>損失関数</strong>を決める<br>
③ 損失関数を「<strong>最小化</strong>」する</p>
<h4 id="%E3%83%A2%E3%83%87%E3%83%AB%E3%82%92%E6%B1%BA%E3%82%81%E3%82%8B">モデルを決める</h4>
<p>今回は単回帰分析なので、モデルは以下のようになります。</p>
<p>$$
\hat{y}_i = a + bx_i
$$</p>
<h4 id="%E6%90%8D%E5%A4%B1%E9%96%A2%E6%95%B0%E3%82%92%E6%B1%BA%E3%82%81%E3%82%8B">損失関数を決める</h4>
<p><strong>最小二乗法</strong>によって求めるので、損失関数は以下のようになります。</p>
<p><img src="stats15-1.png" alt="リンクテキスト"></p>
<h4 id="%E6%90%8D%E5%A4%B1%E9%96%A2%E6%95%B0%E3%82%92%E6%9C%80%E5%B0%8F%E5%8C%96%E3%81%99%E3%82%8B">損失関数を「最小化」する</h4>
<p>損失関数を計算すると、以下のような結果が得られます。</p>
<p>$a=\bar{y}-b\bar{x}  $<br>
$b=r\frac{s_y}{s_x}$</p>
<ul>
<li>$S_y$：$y$の標準偏差</li>
<li>$S_x$：$x$の標準偏差</li>
<li>$r_{xy}$：$x$と $y$ の相関係数</li>
</ul>
<p>（答えの導出過程は<a href="https://bellcurve.jp/statistics/course/24375.html">こちら</a>や『データ活用基礎』第5回プリント課題の解答を参照してください。）</p>
<div style="page-break-before:always"></div>
<h3 id="python%E3%81%AB%E3%82%88%E3%82%8B%E6%8F%8F%E7%94%BB">Pythonによる描画</h3>
<p>身長から体重を予測することを例として、回帰直線を求めてみましょう。</p>
<pre class="hljs"><code><div>weight = np.array([<span class="hljs-number">68</span>, <span class="hljs-number">84</span>, <span class="hljs-number">68</span>, <span class="hljs-number">87</span>, <span class="hljs-number">78</span>, <span class="hljs-number">84</span>, <span class="hljs-number">76</span>, <span class="hljs-number">74</span>, <span class="hljs-number">66</span>, <span class="hljs-number">72</span>, <span class="hljs-number">67</span>, <span class="hljs-number">67</span>])
height = np.array([<span class="hljs-number">174</span>, <span class="hljs-number">187</span>, <span class="hljs-number">170</span>, <span class="hljs-number">189</span>, <span class="hljs-number">185</span>, <span class="hljs-number">187</span>, <span class="hljs-number">178</span>, <span class="hljs-number">177</span>, <span class="hljs-number">176</span>, <span class="hljs-number">180</span>, <span class="hljs-number">173</span>, <span class="hljs-number">173</span>])

sns.regplot(height, weight)  <span class="hljs-comment"># 回帰直線の描画</span>
plt.scatter(height, weight)  <span class="hljs-comment"># 散布図の描画</span>
plt.xlabel(<span class="hljs-string">'height'</span>)
plt.ylabel(<span class="hljs-string">'weight'</span>)
plt.xlim(<span class="hljs-number">167.5</span>,<span class="hljs-number">190</span>)
</div></code></pre>
<pre><code>(167.5, 190.0)
</code></pre>
<p><img src="output_32_2.png" alt="png"></p>
<div style="page-break-before:always"></div>
<p>次はscikit-learnを使って描画してみます。</p>
<p>理屈については今回触れないので<br>
気になる方は<a href="https://datawokagaku.com/linear_reg_implement/">こちら</a>などを参照してください。</p>
<pre class="hljs"><code><div><span class="hljs-comment"># 学習のためのインスタンス作成</span>
reg = LinearRegression()

<span class="hljs-string">"""
fitメソッドで学習する
.fit(x,y)に入れる"x"は、行列である必要がある
"""</span>
X = np.expand_dims(height, axis=<span class="hljs-number">-1</span>)  <span class="hljs-comment"># 次元を1つ追加して「ベクトル→行列」にする</span>
y = weight
reg.fit(X, y)

<span class="hljs-comment"># "a"と"b"の表示 </span>
print(<span class="hljs-string">"b={}"</span>.format(reg.coef_))
print(<span class="hljs-string">"a={}"</span>.format(reg.intercept_))
</div></code></pre>
<pre><code>b=[1.09812147]
a=-122.40525259894213
</code></pre>
<p>以下の式が成り立つか確認してみましょう。</p>
<p>$a=\bar{y}-b\bar{x}  $<br>
$b=r\frac{s_y}{s_x}$</p>
<pre class="hljs"><code><div><span class="hljs-comment"># 標準偏差</span>
s_x = np.std(height)
s_y = np.std(weight)
<span class="hljs-comment"># 平均</span>
mean_x = np.mean(height)
mean_y = np.mean(weight)
<span class="hljs-comment"># 相関係数</span>
r = np.corrcoef(weight, height)[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>]
b = r * s_y/s_x
a = mean_y - b*mean_x
print(<span class="hljs-string">"b={}"</span>.format(b))
print(<span class="hljs-string">"a={}"</span>.format(a))
</div></code></pre>
<pre><code>b=1.0981214663505376
a=-122.40525259894213
</code></pre>
<div style="page-break-before:always"></div>
<p>では求めた$a$と$b$から回帰直線を描画してみましょう。</p>
<pre class="hljs"><code><div><span class="hljs-comment"># x軸の値作成</span>
x = np.arange(<span class="hljs-number">167.5</span>, <span class="hljs-number">190</span>, <span class="hljs-number">1</span>)
plt.plot(x, b*x+a, )
<span class="hljs-comment"># seaborn のregplotも合わせて描画する．</span>
sns.regplot(height, weight)
plt.xlabel(<span class="hljs-string">'height'</span>)
plt.ylabel(<span class="hljs-string">'weight'</span>)
</div></code></pre>
<p><img src="output_38_2.png" alt="png"></p>
<p>先ほど描画したregplotとぴったり重なっていますね。</p>
<p>学習済みのモデルができたので、175cmの体重を予測してみましょう。</p>
<pre class="hljs"><code><div>X = np.array([[<span class="hljs-number">175</span>]])
y = reg.predict(X)
print(X, y)
</div></code></pre>
<pre><code>[[175]] [69.76600401]
</code></pre>
<p>約69.8kgと予測しています。</p>
<div style="page-break-before:always"></div>
<h3 id="%E9%83%BD%E9%81%93%E5%BA%9C%E7%9C%8C%E3%83%87%E3%83%BC%E3%82%BF%E3%81%A7%E5%8D%98%E5%9B%9E%E5%B8%B0%E5%88%86%E6%9E%90">都道府県データで単回帰分析</h3>
<p>統計編の資料で再三登場したtodohuken_kaidata.csvを使います。</p>
<p>インポートしてください。</p>
<pre class="hljs"><code><div>df = pd.read_csv(<span class="hljs-string">"todohuken_kaidata.csv"</span>)
df.head(<span class="hljs-number">1</span>)
</div></code></pre>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>都道府県</th>
      <th>地方</th>
      <th>15歳以上の平均睡眠時間（男）</th>
      <th>15歳以上の平均睡眠時間（女）</th>
      <th>運転免許保有者割合（%）</th>
      <th>農業従事者（人口100人あたり）</th>
      <th>平均通勤時間（片道）</th>
      <th>自動車保有台数（人口100人あたり）</th>
      <th>鉄道旅客輸送量(人口一人あたり)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>北海道</td>
      <td>北海道地方</td>
      <td>473</td>
      <td>465</td>
      <td>63.4</td>
      <td>1.79</td>
      <td>20.2</td>
      <td>68.67</td>
      <td>65.9</td>
    </tr>
  </tbody>
</table>
</div>
<div style="page-break-before:always"></div>
<p>まずは相関関係についてみてみましょう。</p>
<pre class="hljs"><code><div>df.corr()
</div></code></pre>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>15歳以上の平均睡眠時間（男）</th>
      <th>15歳以上の平均睡眠時間（女）</th>
      <th>運転免許保有者割合（%）</th>
      <th>農業従事者（人口100人あたり）</th>
      <th>平均通勤時間（片道）</th>
      <th>自動車保有台数（人口100人あたり）</th>
      <th>鉄道旅客輸送量(人口一人あたり)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>15歳以上の平均睡眠時間（男）</th>
      <td>1.000000</td>
      <td>0.825764</td>
      <td>0.400987</td>
      <td>0.822237</td>
      <td>-0.781084</td>
      <td>0.610426</td>
      <td>-0.595017</td>
    </tr>
    <tr>
      <th>15歳以上の平均睡眠時間（女）</th>
      <td>0.825764</td>
      <td>1.000000</td>
      <td>0.246533</td>
      <td>0.749536</td>
      <td>-0.554681</td>
      <td>0.433637</td>
      <td>-0.338663</td>
    </tr>
    <tr>
      <th>運転免許保有者割合（%）</th>
      <td>0.400987</td>
      <td>0.246533</td>
      <td>1.000000</td>
      <td>0.576308</td>
      <td>-0.635377</td>
      <td>0.925849</td>
      <td>-0.751471</td>
    </tr>
    <tr>
      <th>農業従事者（人口100人あたり）</th>
      <td>0.822237</td>
      <td>0.749536</td>
      <td>0.576308</td>
      <td>1.000000</td>
      <td>-0.696542</td>
      <td>0.719500</td>
      <td>-0.629990</td>
    </tr>
    <tr>
      <th>平均通勤時間（片道）</th>
      <td>-0.781084</td>
      <td>-0.554681</td>
      <td>-0.635377</td>
      <td>-0.696542</td>
      <td>1.000000</td>
      <td>-0.826087</td>
      <td>0.786965</td>
    </tr>
    <tr>
      <th>自動車保有台数（人口100人あたり）</th>
      <td>0.610426</td>
      <td>0.433637</td>
      <td>0.925849</td>
      <td>0.719500</td>
      <td>-0.826087</td>
      <td>1.000000</td>
      <td>-0.872011</td>
    </tr>
    <tr>
      <th>鉄道旅客輸送量(人口一人あたり)</th>
      <td>-0.595017</td>
      <td>-0.338663</td>
      <td>-0.751471</td>
      <td>-0.629990</td>
      <td>0.786965</td>
      <td>-0.872011</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>
<div style="page-break-before:always"></div>
<p>今回は男性の平均睡眠時間と平均通勤時間について単回帰分析を行ってみます。</p>
<pre class="hljs"><code><div>man_sleep = df[<span class="hljs-string">"15歳以上の平均睡眠時間（男）"</span>]
commute_time = df[<span class="hljs-string">"平均通勤時間（片道）"</span>]

<span class="hljs-comment"># 学習のためのインスタンス作成</span>
reg = LinearRegression()

<span class="hljs-string">"""
fitメソッドで学習する
.fit(x,y)に入れる"x"は、行列である必要がある
"""</span>
X = np.expand_dims(man_sleep, axis=<span class="hljs-number">-1</span>)  <span class="hljs-comment"># 次元を1つ追加して「ベクトル→行列」にする</span>
y = commute_time
reg.fit(X, y)

b = reg.coef_
a = reg.intercept_

<span class="hljs-comment"># "a"と"b"の表示 </span>
print(<span class="hljs-string">"b={}"</span>.format(reg.coef_))
print(<span class="hljs-string">"a={}"</span>.format(reg.intercept_))
</div></code></pre>
<pre><code>b=[-0.76915791]
a=384.67574380901476
</code></pre>
<div style="page-break-before:always"></div>
<pre class="hljs"><code><div><span class="hljs-comment"># x軸の値作成</span>
x = np.arange(<span class="hljs-number">450</span>, <span class="hljs-number">490</span>, <span class="hljs-number">1</span>)
plt.plot(x, b*x+a, )
plt.xlabel(<span class="hljs-string">'man_sleep'</span>)
plt.ylabel(<span class="hljs-string">'commute_time'</span>)
</div></code></pre>
<p><img src="output_50_1.png" alt="png"></p>
<pre class="hljs"><code><div><span class="hljs-comment"># 8時間睡眠している男性の平均通勤時間は？</span>
X = np.array([[<span class="hljs-number">480</span>]])
y = reg.predict(X)
print(X, y)  <span class="hljs-comment"># 約15分！（そんなバカな）</span>
</div></code></pre>
<pre><code>[[480]] [15.47994833]
</code></pre>
<div style="page-break-before:always"></div>
<h3 id="%E8%AA%AC%E6%98%8E%E5%A4%89%E6%95%B0%E3%81%A8%E7%9B%AE%E7%9A%84%E5%A4%89%E6%95%B0%E3%81%AE%E5%85%A5%E3%82%8C%E6%9B%BF%E3%81%88">説明変数と目的変数の入れ替え</h3>
<p>入れ替えてみるとどうなるのでしょうか？<br>
$a$と$b$を入れ替えてみた結果はこちらです。</p>
<p>$a^{'}=\bar{x}-b^{'}\bar{x}  $</p>
<p>$b^{'}=r\frac{s_x}{s_y}$</p>
<p>説明変数と目的変数を入れ替えると、別の回帰直線ができあがります。</p>
<pre class="hljs"><code><div>weight = np.array([<span class="hljs-number">68</span>, <span class="hljs-number">84</span>, <span class="hljs-number">68</span>, <span class="hljs-number">87</span>, <span class="hljs-number">78</span>, <span class="hljs-number">84</span>, <span class="hljs-number">76</span>, <span class="hljs-number">74</span>, <span class="hljs-number">66</span>, <span class="hljs-number">72</span>, <span class="hljs-number">67</span>, <span class="hljs-number">67</span>])
height = np.array([<span class="hljs-number">174</span>, <span class="hljs-number">187</span>, <span class="hljs-number">170</span>, <span class="hljs-number">189</span>, <span class="hljs-number">185</span>, <span class="hljs-number">187</span>, <span class="hljs-number">178</span>, <span class="hljs-number">177</span>, <span class="hljs-number">176</span>, <span class="hljs-number">180</span>, <span class="hljs-number">173</span>, <span class="hljs-number">173</span>])

<span class="hljs-comment"># reg1: heightからweightを予測する回帰直線</span>
X = np.expand_dims(height, axis=<span class="hljs-number">-1</span>)
y = weight
reg1 = LinearRegression()
reg1.fit(X, y)
 
<span class="hljs-comment"># reg2: weightからheightを予測する回帰直線</span>
X = np.expand_dims(weight, axis=<span class="hljs-number">-1</span>)
y = height
reg2 = LinearRegression()
reg2.fit(X, y)
 
x = np.arange(<span class="hljs-number">170</span>, <span class="hljs-number">190</span>, <span class="hljs-number">1</span>)
plt.scatter(height, weight)

plt.plot(x, x*reg1.coef_+reg1.intercept_, <span class="hljs-string">'b'</span>)
<span class="hljs-comment"># reg2を描画(x=a'+b'yを変形し，y=(x-a')/b')となることに注意</span>
plt.plot(x, (x-reg2.intercept_)/reg2.coef_, <span class="hljs-string">'r'</span>)
<span class="hljs-comment"># reg1とreg2が交差している点がweightとheightの平均の点</span>
plt.plot(np.mean(height), np.mean(weight), <span class="hljs-string">'ro'</span>)
plt.xlabel(<span class="hljs-string">'height'</span>)
plt.ylabel(<span class="hljs-string">'weight'</span>)
</div></code></pre>
<p><img src="output_55_1.png" alt="png"></p>
<p>どちらの回帰直線も$(\bar{x} , \bar{y})$ を通るので、<br>
$(\bar{x} , \bar{y})$ で交わっています。</p>
<pre class="hljs"><code><div>print(<span class="hljs-string">f"体重の平均：<span class="hljs-subst">{np.mean(weight)}</span>"</span>)
print(<span class="hljs-string">f"身長の平均：<span class="hljs-subst">{np.mean(height)}</span>"</span>)
</div></code></pre>
<pre><code>体重の平均：74.25
身長の平均：179.08333333333334
</code></pre>
<p>とる目的変数によって回帰直線が変化してしまうので注意が必要です。</p>
<div style="page-break-before:always"></div>
<h2 id="%E6%B1%BA%E5%AE%9A%E4%BF%82%E6%95%B0">決定係数</h2>
<p>「説明変数がどれだけ目的変数の値を説明しているかの指標」を<strong>決定係数</strong>といいます。</p>
<p>一般的に$R^2$で示され、0から1までの値をとります。<br>
1に近いほど、回帰式が実際のデータに当てはまっていることを表しています。</p>
<p>基準の目安は以下の通りです。<br>
（参考：https://istat.co.jp/ta_commentary/multiple_02 ）</p>
<ul>
<li><strong>0.8以上</strong>：精度良い</li>
<li><strong>0.5~0.8</strong>：精度やや良い</li>
<li><strong>0.5以下</strong>：精度良くない</li>
</ul>
<div style="page-break-before:always"></div>
<h3 id="%E6%B1%BA%E5%AE%9A%E4%BF%82%E6%95%B0%E3%81%AE%E5%AE%9A%E7%BE%A9">決定係数の定義</h3>
<p><img src="https://imgur.com/gsoWMOU.png" alt="リンクテキスト"></p>
<p>①：全変動：実測値とデータ全体の平均値との差<br>
②：回帰変動：予測値とデータ全体の平均値との差<br>
③：残差変動：実測値と予測値との差</p>
<p>②の回帰変動は「回帰直線によって説明できた部分」、<br>
③の残差変動は「回帰直線によって説明できなかった部分」となります。</p>
<p>（<a href="https://bit.ly/3XZs1IQ">こちら</a>などに書かれている証明によって）以下の式が成り立ちます。</p>
<p>$$
\sum (y_i-\bar{y})^2 = \sum(\hat{y}_i-\bar{y})^2 + \sum(y_i-\hat{y}_i)^2
$$</p>
<p>決定係数は「回帰変動が全変動に対してどれだけ多いか」を表すものなので、<br>
決定係数は回帰変動を全変動で割ることで求められます。</p>
<p>$$
R^2 = \frac{\sum(\hat{y}_i-\bar{y})^2}{\sum (y_i-\bar{y})^2} = 1-\frac{\sum(y_i-\hat{y}_i)^2}{\sum (y_i-\bar{y})^2}
$$</p>
<p><strong>回帰直線が最小二乗法によって求められた場合、この$R$は相関係数$r$と一致します</strong>。<br>
重要なので覚えておきましょう。</p>
<div style="page-break-before:always"></div>
<h3 id="python%E3%81%AB%E3%82%88%E3%82%8B%E6%B1%BA%E5%AE%9A%E4%BF%82%E6%95%B0%E3%81%AE%E5%B0%8E%E5%87%BA">Pythonによる決定係数の導出</h3>
<p>適当に身長と体重のデータを用意したので、決定係数を求めてみましょう。</p>
<pre class="hljs"><code><div><span class="hljs-comment"># 学習データ</span>
weight = np.array([<span class="hljs-number">68</span>, <span class="hljs-number">84</span>, <span class="hljs-number">68</span>, <span class="hljs-number">87</span>, <span class="hljs-number">78</span>, <span class="hljs-number">84</span>, <span class="hljs-number">76</span>, <span class="hljs-number">74</span>, <span class="hljs-number">66</span>, <span class="hljs-number">72</span>, <span class="hljs-number">67</span>, <span class="hljs-number">67</span>])
height = np.array([<span class="hljs-number">174</span>, <span class="hljs-number">187</span>, <span class="hljs-number">170</span>, <span class="hljs-number">189</span>, <span class="hljs-number">185</span>, <span class="hljs-number">187</span>, <span class="hljs-number">178</span>, <span class="hljs-number">177</span>, <span class="hljs-number">176</span>, <span class="hljs-number">180</span>, <span class="hljs-number">173</span>, <span class="hljs-number">173</span>])

<span class="hljs-comment"># モデルの作成と学習</span>
reg = LinearRegression()

X = np.expand_dims(height, axis=<span class="hljs-number">-1</span>)
y = weight
reg.fit(X, y)
</div></code></pre>
<pre class="hljs"><code><div><span class="hljs-comment"># 評価データ</span>
weight_test = np.array([<span class="hljs-number">64</span>, <span class="hljs-number">88</span>, <span class="hljs-number">75</span>, <span class="hljs-number">72</span>, <span class="hljs-number">75</span>, <span class="hljs-number">84</span>, <span class="hljs-number">64</span>, <span class="hljs-number">75</span>, <span class="hljs-number">70</span>, <span class="hljs-number">73</span>, <span class="hljs-number">71</span>, <span class="hljs-number">68</span>])
height_test = np.array([<span class="hljs-number">172</span>, <span class="hljs-number">197</span>, <span class="hljs-number">183</span>, <span class="hljs-number">178</span>, <span class="hljs-number">186</span>, <span class="hljs-number">188</span>, <span class="hljs-number">175</span>, <span class="hljs-number">175</span>, <span class="hljs-number">180</span>, <span class="hljs-number">178</span>, <span class="hljs-number">173</span>, <span class="hljs-number">174</span>])

<span class="hljs-comment"># 予測値</span>
X_test = np.expand_dims(height_test, axis=<span class="hljs-number">-1</span>)
y_test_pred = reg.predict(X_test)
</div></code></pre>
<pre class="hljs"><code><div><span class="hljs-comment"># 決定係数</span>
r2_score(weight_test, y_test_pred)
</div></code></pre>
<pre><code>0.6376269742887806
</code></pre>
<div style="page-break-before:always"></div>
<h2 id="%E9%87%8D%E5%9B%9E%E5%B8%B0%E5%88%86%E6%9E%90">重回帰分析</h2>
<p>複数の説明変数 $x_i$ ($i=1,2,3,…n$)を用いて目的変数$y$を表す回帰分析を<br>
<strong>重回帰分析</strong>といいます。</p>
<h3 id="%E9%87%8D%E5%9B%9E%E5%B8%B0%E5%88%86%E6%9E%90%E3%81%AE%E6%B5%81%E3%82%8C">重回帰分析の流れ</h3>
<p>① <strong>モデル</strong>を決める<br>
② <strong>損失関数</strong>を決める<br>
③ 損失関数を「<strong>最小化</strong>」する</p>
<h4 id="%E3%83%A2%E3%83%87%E3%83%AB%E3%82%92%E6%B1%BA%E3%82%81%E3%82%8B">モデルを決める</h4>
<p>今回は特徴量が複数なので、各データの値を$x_{ij}$とし、<br>
$j$番目の特徴量の$i$番目のデータという風にします。</p>
<p>予測値 $\hat{y}_i$ は以下の式で表されます。</p>
<p><img src="stats15-6.png" alt="リンクテキスト"></p>
<p>説明変数の重要度が高いものはパラメータ $\theta$ の値が大きくなります。</p>
<p>単回帰分析のときと同様、多少の誤差を考慮する必要があります。<br>
これを $b$（<strong>バイアス</strong>）で表します。</p>
<p>式を書き直すと以下のようになります。</p>
<p><img src="stats15-2.png" alt="リンクテキスト"></p>
<p>$b = \theta_0×x_0 = \theta_0×1$ とダミーの変数を用いることで、<br>
形式を他の項に合わせることができます。</p>
<p><img src="stats15-3.png" alt="リンクテキスト"></p>
<div style="page-break-before:always"></div>
<p>これを行列の形に変形します。</p>
<p><img src="stats15-4.png" alt="リンクテキスト"></p>
<p>それぞれの行列およびベクトルを $\mathbf{\hat{y}},\mathbf{X},\theta$ とすると、</p>
<p>$$
\mathbf{\hat{y}}=\mathbf{X}\mathbf{\theta}
$$</p>
<p>と表すことができます。</p>
<h4 id="%E6%90%8D%E5%A4%B1%E9%96%A2%E6%95%B0%E3%82%92%E6%B1%BA%E3%82%81%E3%82%8B">損失関数を決める</h4>
<p>基本は単回帰分析のときと同様です。</p>
<p><img src="stats15-5.png" alt="リンクテキスト"></p>
<h4 id="%E6%90%8D%E5%A4%B1%E9%96%A2%E6%95%B0%E3%82%92%E6%9C%80%E5%B0%8F%E5%8C%96%E3%81%99%E3%82%8B">損失関数を「最小化」する</h4>
<p>損失関数を計算すると、以下のような結果が得られます。</p>
<p>$$
\theta=(\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{y}
$$</p>
<p>（答えの導出過程は<a href="https://bit.ly/3lTzKuL">こちら</a>や『データサイエンス入門』第7回講義資料を参照してください。）</p>
<p>この式は<strong>正規方程式</strong>と呼ばれます。</p>
<div style="page-break-before:always"></div>
<h1 id="%E7%B5%82%E3%82%8F%E3%82%8A%E3%81%AB">終わりに</h1>
<p>Pythonで重回帰分析を行おうとすると重たくなってしまうので<br>
本資料はここまでとします。</p>

</body>
</html>
